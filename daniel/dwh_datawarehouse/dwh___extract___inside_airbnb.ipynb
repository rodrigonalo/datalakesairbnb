{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02a8a99f-e52c-42b8-b04a-dfbe52baf852",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Data Cleaning: InsideAirbnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75eaf0cc-b7d0-4b9a-816c-e4407b30c75d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# For Azure connection:\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from io import BytesIO\n",
    "import io\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "455a6c7f-c689-47e2-9463-54c99e69d773",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Loading data from Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure Blob Storage\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=datalakestoragerentscape;AccountKey=w6Edf3np1A18vQIei31unvKWjGpyDUBqexvVauAwCeqOmnF1Bq7WsIEVplSEW+hT0q4ZzDi2KNh4+AStrOcI6g==;EndpointSuffix=core.windows.net\"\n",
    "container_name = \"rentscape-blob\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Azure Blob Storage.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    print(\"Connected to Azure Blob Storage.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to connect to Azure Blob Storage:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rentscape-blob\n",
      "+---barcelona_listings.csv\n",
      "+---barcelona_reviews.csv\n",
      "+---prague_listings.csv\n",
      "+---prague_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "blob_list = container_client.list_blobs()\n",
    "print(container_name)\n",
    "for blob in blob_list:\n",
    "    print(f\"+---{blob.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a CSV file from Azure Blob Storage into a Pandas DataFrame\n",
    "def load_csv_from_blob(blob_path):\n",
    "    blob_client = container_client.get_blob_client(blob_path)\n",
    "    stream = BytesIO(blob_client.download_blob().readall())\n",
    "    return pd.read_csv(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning listings data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the `listings.csv` dataset from both cities, and will proceed to unify and clean the data according to the correct data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the Prague and Barcelona listings\n",
    "try:\n",
    "    prg_listings_raw = load_csv_from_blob(\"prague_listings.csv\")\n",
    "    bcn_listings_raw = load_csv_from_blob(\"barcelona_listings.csv\")\n",
    "    print(\"Data loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load data from Azure Blob Storage:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data sets we will work with separately, to preserve the raw data\n",
    "prg_listings = prg_listings_raw\n",
    "bcn_listings = bcn_listings_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>picture_url</th>\n",
       "      <th>host_id</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>license</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23163</td>\n",
       "      <td>https://www.airbnb.com/rooms/23163</td>\n",
       "      <td>20240624031252</td>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>previous scrape</td>\n",
       "      <td>Residence Karolina - KAROL12</td>\n",
       "      <td>Unique and elegant apartment rental in Prague,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/01bbe32c-3f13...</td>\n",
       "      <td>5282</td>\n",
       "      <td>...</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23169</td>\n",
       "      <td>https://www.airbnb.com/rooms/23169</td>\n",
       "      <td>20240624031252</td>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Residence Masna - Masna302</td>\n",
       "      <td>Masna studio offers a lot of space and privacy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/b450cf2a-8561...</td>\n",
       "      <td>5282</td>\n",
       "      <td>...</td>\n",
       "      <td>4.86</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                         listing_url       scrape_id last_scraped  \\\n",
       "0  23163  https://www.airbnb.com/rooms/23163  20240624031252   2024-06-24   \n",
       "1  23169  https://www.airbnb.com/rooms/23169  20240624031252   2024-06-24   \n",
       "\n",
       "            source                          name  \\\n",
       "0  previous scrape  Residence Karolina - KAROL12   \n",
       "1      city scrape    Residence Masna - Masna302   \n",
       "\n",
       "                                         description neighborhood_overview  \\\n",
       "0  Unique and elegant apartment rental in Prague,...                   NaN   \n",
       "1  Masna studio offers a lot of space and privacy...                   NaN   \n",
       "\n",
       "                                         picture_url  host_id  ...  \\\n",
       "0  https://a0.muscache.com/pictures/01bbe32c-3f13...     5282  ...   \n",
       "1  https://a0.muscache.com/pictures/b450cf2a-8561...     5282  ...   \n",
       "\n",
       "  review_scores_communication review_scores_location review_scores_value  \\\n",
       "0                        4.97                   4.93                4.86   \n",
       "1                        4.86                   4.97                4.69   \n",
       "\n",
       "  license instant_bookable calculated_host_listings_count  \\\n",
       "0     NaN                t                             70   \n",
       "1     NaN                t                             70   \n",
       "\n",
       "  calculated_host_listings_count_entire_homes  \\\n",
       "0                                          69   \n",
       "1                                          69   \n",
       "\n",
       "  calculated_host_listings_count_private_rooms  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "\n",
       "  calculated_host_listings_count_shared_rooms reviews_per_month  \n",
       "0                                           0              0.19  \n",
       "1                                           0              0.70  \n",
       "\n",
       "[2 rows x 75 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prg_listings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'listing_url',\n",
       " 'scrape_id',\n",
       " 'last_scraped',\n",
       " 'source',\n",
       " 'name',\n",
       " 'description',\n",
       " 'neighborhood_overview',\n",
       " 'picture_url',\n",
       " 'host_id',\n",
       " 'host_url',\n",
       " 'host_name',\n",
       " 'host_since',\n",
       " 'host_location',\n",
       " 'host_about',\n",
       " 'host_response_time',\n",
       " 'host_response_rate',\n",
       " 'host_acceptance_rate',\n",
       " 'host_is_superhost',\n",
       " 'host_thumbnail_url',\n",
       " 'host_picture_url',\n",
       " 'host_neighbourhood',\n",
       " 'host_listings_count',\n",
       " 'host_total_listings_count',\n",
       " 'host_verifications',\n",
       " 'host_has_profile_pic',\n",
       " 'host_identity_verified',\n",
       " 'neighbourhood',\n",
       " 'neighbourhood_cleansed',\n",
       " 'neighbourhood_group_cleansed',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'property_type',\n",
       " 'room_type',\n",
       " 'accommodates',\n",
       " 'bathrooms',\n",
       " 'bathrooms_text',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'amenities',\n",
       " 'price',\n",
       " 'minimum_nights',\n",
       " 'maximum_nights',\n",
       " 'minimum_minimum_nights',\n",
       " 'maximum_minimum_nights',\n",
       " 'minimum_maximum_nights',\n",
       " 'maximum_maximum_nights',\n",
       " 'minimum_nights_avg_ntm',\n",
       " 'maximum_nights_avg_ntm',\n",
       " 'calendar_updated',\n",
       " 'has_availability',\n",
       " 'availability_30',\n",
       " 'availability_60',\n",
       " 'availability_90',\n",
       " 'availability_365',\n",
       " 'calendar_last_scraped',\n",
       " 'number_of_reviews',\n",
       " 'number_of_reviews_ltm',\n",
       " 'number_of_reviews_l30d',\n",
       " 'first_review',\n",
       " 'last_review',\n",
       " 'review_scores_rating',\n",
       " 'review_scores_accuracy',\n",
       " 'review_scores_cleanliness',\n",
       " 'review_scores_checkin',\n",
       " 'review_scores_communication',\n",
       " 'review_scores_location',\n",
       " 'review_scores_value',\n",
       " 'license',\n",
       " 'instant_bookable',\n",
       " 'calculated_host_listings_count',\n",
       " 'calculated_host_listings_count_entire_homes',\n",
       " 'calculated_host_listings_count_private_rooms',\n",
       " 'calculated_host_listings_count_shared_rooms',\n",
       " 'reviews_per_month']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prg_listings.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Praha 1',\n",
       " 'Praha 2',\n",
       " 'Praha 3',\n",
       " 'Praha 5',\n",
       " 'Praha 8',\n",
       " 'Praha 15',\n",
       " 'Dolní Měcholupy',\n",
       " 'Praha 9',\n",
       " 'Praha 7',\n",
       " 'Praha 10',\n",
       " 'Praha 6',\n",
       " 'Praha 4',\n",
       " 'Praha 14',\n",
       " 'Praha 13',\n",
       " 'Velká Chuchle',\n",
       " 'Kunratice',\n",
       " 'Zličín',\n",
       " 'Dubeč',\n",
       " 'Zbraslav',\n",
       " 'Petrovice',\n",
       " 'Praha 12',\n",
       " 'Praha 11',\n",
       " 'Praha 21',\n",
       " 'Praha 16',\n",
       " 'Praha 17',\n",
       " 'Šeberov',\n",
       " 'Klánovice',\n",
       " 'Štěrboholy',\n",
       " 'Slivenec',\n",
       " 'Újezd',\n",
       " 'Ďáblice',\n",
       " 'Dolní Počernice',\n",
       " 'Praha 18',\n",
       " 'Praha 20',\n",
       " 'Libuš',\n",
       " 'Řeporyje',\n",
       " 'Březiněves',\n",
       " 'Nebušice',\n",
       " 'Satalice',\n",
       " 'Praha 22',\n",
       " 'Troja',\n",
       " 'Dolní Chabry',\n",
       " 'Čakovice',\n",
       " 'Praha 19',\n",
       " 'Lipence',\n",
       " 'Lysolaje',\n",
       " 'Vinoř',\n",
       " 'Nedvězí',\n",
       " 'Koloděje',\n",
       " 'Přední Kopanina',\n",
       " 'Suchdol',\n",
       " 'Kolovraty']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_neighbourhoods = prg_listings[\"neighbourhood_cleansed\"].unique().tolist()\n",
    "unique_neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['la Sagrada Família',\n",
       " 'el Besòs i el Maresme',\n",
       " \"el Camp d'en Grassot i Gràcia Nova\",\n",
       " 'el Barri Gòtic',\n",
       " 'Sant Pere, Santa Caterina i la Ribera',\n",
       " 'la Barceloneta',\n",
       " \"la Dreta de l'Eixample\",\n",
       " \"el Camp de l'Arpa del Clot\",\n",
       " 'Sant Antoni',\n",
       " 'el Poblenou',\n",
       " 'la Vila Olímpica del Poblenou',\n",
       " 'les Corts',\n",
       " 'la Vila de Gràcia',\n",
       " 'Vallcarca i els Penitents',\n",
       " 'el Raval',\n",
       " 'la Font de la Guatlla',\n",
       " 'el Parc i la Llacuna del Poblenou',\n",
       " 'el Fort Pienc',\n",
       " \"la Nova Esquerra de l'Eixample\",\n",
       " 'el Clot',\n",
       " 'el Poble Sec',\n",
       " 'Diagonal Mar i el Front Marítim del Poblenou',\n",
       " 'el Coll',\n",
       " 'Sants',\n",
       " 'Pedralbes',\n",
       " 'el Guinardó',\n",
       " 'el Putxet i el Farró',\n",
       " \"l'Antiga Esquerra de l'Eixample\",\n",
       " 'Sant Gervasi - Galvany',\n",
       " 'Sants - Badal',\n",
       " 'el Baix Guinardó',\n",
       " 'el Congrés i els Indians',\n",
       " 'Navas',\n",
       " 'la Bordeta',\n",
       " 'Sant Martí de Provençals',\n",
       " 'la Maternitat i Sant Ramon',\n",
       " 'Sarrià',\n",
       " 'la Prosperitat',\n",
       " 'el Turó de la Peira',\n",
       " 'Provençals del Poblenou',\n",
       " \"la Font d'en Fargues\",\n",
       " 'el Carmel',\n",
       " 'Hostafrancs',\n",
       " 'la Salut',\n",
       " 'les Tres Torres',\n",
       " 'Vallvidrera, el Tibidabo i les Planes',\n",
       " 'la Teixonera',\n",
       " 'Sant Gervasi - la Bonanova',\n",
       " 'Can Baró',\n",
       " 'la Trinitat Vella',\n",
       " 'Porta',\n",
       " 'Vilapicina i la Torre Llobeta',\n",
       " 'la Marina del Prat Vermell',\n",
       " 'la Verneda i la Pau',\n",
       " 'la Marina de Port',\n",
       " 'la Sagrera',\n",
       " 'Sant Andreu',\n",
       " 'Verdun',\n",
       " 'la Guineueta',\n",
       " 'el Bon Pastor',\n",
       " 'Horta',\n",
       " 'Sant Genís dels Agudells',\n",
       " \"la Vall d'Hebron\",\n",
       " 'les Roquetes',\n",
       " 'la Trinitat Nova',\n",
       " 'Torre Baró',\n",
       " 'Montbau',\n",
       " 'la Clota',\n",
       " 'Can Peguera',\n",
       " 'Canyelles',\n",
       " 'Baró de Viver']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_neighbourhoods = bcn_listings[\"neighbourhood_cleansed\"].unique().tolist()\n",
    "unique_neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names and order match exactly!\n"
     ]
    }
   ],
   "source": [
    "# Get the column names as a list\n",
    "prg_column_names = prg_listings.columns.tolist()\n",
    "bcn_column_names = bcn_listings.columns.tolist()\n",
    "\n",
    "# Ensure that both data sets contain the same columns\n",
    "assert prg_column_names == bcn_column_names, \"The column names or order do not match!\"\n",
    "print(\"Column names and order match exactly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>listing_url</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scrape_id</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>last_scraped</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>source</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>calculated_host_listings_count</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>calculated_host_listings_count_entire_homes</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>calculated_host_listings_count_private_rooms</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>calculated_host_listings_count_shared_rooms</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>reviews_per_month</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Column Name Data Type\n",
       "0                                             id     int64\n",
       "1                                    listing_url    object\n",
       "2                                      scrape_id     int64\n",
       "3                                   last_scraped    object\n",
       "4                                         source    object\n",
       "..                                           ...       ...\n",
       "70                calculated_host_listings_count     int64\n",
       "71   calculated_host_listings_count_entire_homes     int64\n",
       "72  calculated_host_listings_count_private_rooms     int64\n",
       "73   calculated_host_listings_count_shared_rooms     int64\n",
       "74                             reviews_per_month   float64\n",
       "\n",
       "[75 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with column names and their data types\n",
    "prg_columns_info = pd.DataFrame({\n",
    "    'Column Name': prg_listings.columns,\n",
    "    'Data Type': prg_listings.dtypes\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "prg_columns_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following points cover the cleaning tasks that must be undertaken, based on the above assessment:\n",
    "- **Dates**: Convert all date fields (e.g., `last_scraped`) from string format to proper date type.\n",
    "- **IDs**: Ensure that all ID fields (e.g., `host_id`) are cast to integer type.\n",
    "- **Count Variables**: Verify that all count-related fields (e.g., `number_of_reviews`) are cast to integer type.\n",
    "- **Decimal Numerical Values**: Ensure that all decimal values (e.g., `review_scores_rating`) are cast to float type.\n",
    "- `price`: Interpret the string structure, remove unnecessary characters and cast to float type.\n",
    "- **Boolean Values**: Convert all boolean fields (e.g., `instant_bookable`) to integer type (0 or 1).\n",
    "- Add a `city` column which contains the name of the city of the dataset, to allow identification after merging both datasets.\n",
    "\n",
    "This can be achieved by consolidating all tasks into a single function that can be applied to each dataset, as they share an identical structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Azure Blob Storage.\n"
     ]
    }
   ],
   "source": [
    "container_name = \"bnpapi-rentscape-blob\"\n",
    "\n",
    "try:\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    print(\"Connected to Azure Blob Storage.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to connect to Azure Blob Storage:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnpapi-rentscape-blob\n",
      "+---conversion_rates.csv\n",
      "+---conversion_rates.json\n"
     ]
    }
   ],
   "source": [
    "blob_list = container_client.list_blobs()\n",
    "print(container_name)\n",
    "for blob in blob_list:\n",
    "    print(f\"+---{blob.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_listings(df, name):\n",
    "    print(f\"Dataset: {name} -------------\")\n",
    "    \n",
    "    # Cast date columns from string to datetime\n",
    "    date_columns = ['last_scraped', 'host_since', 'first_review', 'last_review', 'calendar_last_scraped']\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    print(\"- Date columns cast to date type\")\n",
    "    \n",
    "    # Cast ID columns to integer\n",
    "    id_columns = ['id', 'scrape_id', 'host_id']\n",
    "    for col in id_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce', downcast='integer').fillna(0).astype(int)\n",
    "    print(\"- ID columns cast to integer\")\n",
    "    \n",
    "    # Cast count columns to integer\n",
    "    count_columns = [\n",
    "        'host_listings_count', 'host_total_listings_count', 'availability_30', 'availability_60', \n",
    "        'availability_90', 'availability_365', 'number_of_reviews', 'number_of_reviews_ltm', \n",
    "        'number_of_reviews_l30d', 'calculated_host_listings_count', \n",
    "        'calculated_host_listings_count_entire_homes', \n",
    "        'calculated_host_listings_count_private_rooms', \n",
    "        'calculated_host_listings_count_shared_rooms'\n",
    "    ]\n",
    "    for col in count_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce', downcast='integer').fillna(0).astype(int)\n",
    "    print(\"- Count columns cast to integer\")\n",
    "    \n",
    "    # Cast decimal numerical values to float\n",
    "    decimal_columns = [\n",
    "        'latitude', 'longitude', 'review_scores_rating', 'review_scores_accuracy', \n",
    "        'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', \n",
    "        'review_scores_location', 'review_scores_value', 'reviews_per_month'\n",
    "    ]\n",
    "    for col in decimal_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0.0).astype(float)\n",
    "    print(\"- Decimal numerical columns cast to float\")\n",
    "    \n",
    "    # Clean and convert price column to float\n",
    "    if 'price' in df.columns:\n",
    "        df['price'] = df['price'].astype(str)  # Ensure all values are strings\n",
    "        df['price'] = df['price'].str.replace('$', '', regex=False)  # Remove dollar sign\n",
    "        df['price'] = df['price'].str.replace(',', '', regex=False)  # Remove commas\n",
    "        df['price'] = pd.to_numeric(df['price'], errors='coerce')   # Convert to float, keeping NaNs\n",
    "    print(\"- Price column values cleaned and cast to float\")\n",
    "\n",
    "    # Cast boolean values to integer (0/1)\n",
    "    boolean_columns = ['instant_bookable', 'has_availability', 'host_is_superhost', 'host_identity_verified', 'host_has_profile_pic']\n",
    "    for col in boolean_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).str.lower().map({'true': 1, 'false': 0}).fillna(0).astype(int)\n",
    "    print(\"- Boolean values cast to integer\")\n",
    "\n",
    "    # Add a 'city' column with the value of 'name'\n",
    "    df['city'] = name\n",
    "    print(f\"- Added 'city' column with value '{name}' for all rows\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Prague -------------\n",
      "- Date columns cast to date type\n",
      "- ID columns cast to integer\n",
      "- Count columns cast to integer\n",
      "- Decimal numerical columns cast to float\n",
      "- Price column values cleaned and cast to float\n",
      "- Boolean values cast to integer\n",
      "- Added 'city' column with value 'Prague' for all rows\n",
      "Dataset: Barcelona -------------\n",
      "- Date columns cast to date type\n",
      "- ID columns cast to integer\n",
      "- Count columns cast to integer\n",
      "- Decimal numerical columns cast to float\n",
      "- Price column values cleaned and cast to float\n",
      "- Boolean values cast to integer\n",
      "- Added 'city' column with value 'Barcelona' for all rows\n"
     ]
    }
   ],
   "source": [
    "# Apply the cleaning function to both datasets\n",
    "prg_listings_cleaned = clean_listings(prg_listings, \"Prague\")\n",
    "bcn_listings_cleaned = clean_listings(bcn_listings, \"Barcelona\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [InsideAirbnb documentation](https://docs.google.com/spreadsheets/d/1iWCNJcSutYqpULSQHlNyGInUvHg2BoUGoNRIGa6Szc4/edit?gid=1322284596#gid=1322284596) states the following regarding the variable `price`: _daily price in local currency. NOTE: the $ sign is a technical artifact of the export, please ignore it_. For this purpose, the extracted currency exchange value will be applied to the `price` variable of the Prague dataset, in order to unify both to euro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       NaN\n",
       "1    2779.0\n",
       "2    3135.0\n",
       "3    5218.0\n",
       "4    3366.0\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a sample of the updated dataframe\n",
    "prg_listings_cleaned.head()['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load JSON from Azure Blob Storage\n",
    "def load_json_from_blob(connection_string, container_name, blob_name):\n",
    "    # Create a BlobServiceClient\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    \n",
    "    # Download the blob\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    download_stream = blob_client.download_blob()\n",
    "    \n",
    "    # Parse JSON content\n",
    "    return json.loads(download_stream.readall())\n",
    "\n",
    "# Load the JSON file\n",
    "conversion_rates_json = load_json_from_blob(connection_string, container_name, \"conversion_rates.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Date': '2024-11-28',\n",
       "  'CZK_to_PLN': 0.1705,\n",
       "  'EUR_to_PLN': 4.3085,\n",
       "  'CZK_to_EUR': 0.0395729372}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversion_rates_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'CZK_to_EUR' value\n",
    "czk_to_eur_rate = conversion_rates_json[0].get(\"CZK_to_EUR\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           NaN\n",
       "1    109.973192\n",
       "2    124.061158\n",
       "3    206.491586\n",
       "4    133.202507\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the exchange rate to prg_listings_cleaned\n",
    "prg_listings_cleaned[\"price\"] = prg_listings_cleaned[\"price\"] * czk_to_eur_rate\n",
    "\n",
    "# Display a sample of the updated dataframe\n",
    "prg_listings_cleaned.head()['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values summary for dataset: Prague -------------\n",
      "Shape: 9066 rows × 76 columns\n",
      "description                      260\n",
      "neighborhood_overview           4364\n",
      "host_location                   2039\n",
      "host_about                      3686\n",
      "host_response_time               461\n",
      "host_response_rate               461\n",
      "host_acceptance_rate             268\n",
      "host_neighbourhood               644\n",
      "neighbourhood                   4364\n",
      "neighbourhood_group_cleansed    9066\n",
      "bathrooms                        620\n",
      "bathrooms_text                    14\n",
      "bedrooms                         100\n",
      "beds                             630\n",
      "price                            645\n",
      "calendar_updated                9066\n",
      "first_review                     784\n",
      "last_review                      784\n",
      "license                         9066\n",
      "dtype: int64\n",
      "Total missing values: 47322/689016 (6.87%)\n",
      "\n",
      "Missing values summary for dataset: Barcelona -------------\n",
      "Shape: 19482 rows × 76 columns\n",
      "description                817\n",
      "neighborhood_overview     9444\n",
      "host_name                    2\n",
      "host_since                   2\n",
      "host_location             4499\n",
      "host_about                7339\n",
      "host_response_time        3047\n",
      "host_response_rate        3047\n",
      "host_acceptance_rate      2789\n",
      "host_thumbnail_url           2\n",
      "host_picture_url             2\n",
      "host_neighbourhood        9772\n",
      "host_verifications           2\n",
      "neighbourhood             9444\n",
      "bathrooms                 4057\n",
      "bathrooms_text              22\n",
      "bedrooms                  2054\n",
      "beds                      4146\n",
      "price                     4060\n",
      "calendar_updated         19482\n",
      "first_review              4751\n",
      "last_review               4751\n",
      "license                   6194\n",
      "dtype: int64\n",
      "Total missing values: 99725/1480632 (6.74%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df, name):\n",
    "    total_rows, total_columns = df.shape  # Get the number of rows and columns\n",
    "    total_entries = df.size  # Total number of elements (rows * columns)\n",
    "    missing_values = df.isnull().sum()\n",
    "    total_missing = missing_values.sum()  # Total missing values across the entire dataset\n",
    "    \n",
    "    print(f\"Missing values summary for dataset: {name} -------------\")\n",
    "    print(f\"Shape: {total_rows} rows × {total_columns} columns\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "    print(f\"Total missing values: {total_missing}/{total_entries} ({(total_missing / total_entries) * 100:.2f}%)\\n\")\n",
    "\n",
    "# Apply to both datasets\n",
    "check_missing_values(prg_listings_cleaned, \"Prague\")\n",
    "check_missing_values(bcn_listings_cleaned, \"Barcelona\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning reviews data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Azure Blob Storage.\n"
     ]
    }
   ],
   "source": [
    "# Reconnect to InsideAirbnb Blob Storage\n",
    "container_name = \"rentscape-blob\"\n",
    "\n",
    "try:\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    print(\"Connected to Azure Blob Storage.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to connect to Azure Blob Storage:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the Prague and Barcelona reviews\n",
    "container_name = \"rentscape-blob\"\n",
    "\n",
    "try:\n",
    "    prg_reviews_raw = load_csv_from_blob(\"prague_reviews.csv\")\n",
    "    bcn_reviews_raw = load_csv_from_blob(\"barcelona_reviews.csv\")\n",
    "    print(\"Data loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load data from Azure Blob Storage:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data sets we will work with separately, to preserve the raw data\n",
    "prg_reviews = prg_reviews_raw\n",
    "bcn_reviews = bcn_reviews_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23163</td>\n",
       "      <td>101588</td>\n",
       "      <td>2010-09-20</td>\n",
       "      <td>227165</td>\n",
       "      <td>Nathan</td>\n",
       "      <td>Incredible apartment in an ideal location. The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23163</td>\n",
       "      <td>157152</td>\n",
       "      <td>2010-12-22</td>\n",
       "      <td>286036</td>\n",
       "      <td>Hugh</td>\n",
       "      <td>The apartment was huge, we felt like we were s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id      id        date  reviewer_id reviewer_name  \\\n",
       "0       23163  101588  2010-09-20       227165        Nathan   \n",
       "1       23163  157152  2010-12-22       286036          Hugh   \n",
       "\n",
       "                                            comments  \n",
       "0  Incredible apartment in an ideal location. The...  \n",
       "1  The apartment was huge, we felt like we were s...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prg_reviews.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names and order match exactly!\n"
     ]
    }
   ],
   "source": [
    "# Get the column names as a list\n",
    "prg_column_names = prg_reviews.columns.tolist()\n",
    "bcn_column_names = bcn_reviews.columns.tolist()\n",
    "\n",
    "# Ensure that both data sets contain the same columns\n",
    "assert prg_column_names == bcn_column_names, \"The column names or order do not match!\"\n",
    "print(\"Column names and order match exactly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following points cover the cleaning tasks that must be undertaken, based on the above assessment:\n",
    "- **IDs**: Ensure that all ID fields (`listing_id`, `id`, `reviewer_id`) are cast to integer type.\n",
    "- **Dates**: Convert the `date` field from string format to proper date type.\n",
    "\n",
    "This can be achieved by consolidating all tasks into a single function that can be applied to each dataset, as they share an identical structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reviews(df, name):\n",
    "    print(f\"Dataset: {name} -------------\")\n",
    "    \n",
    "    # Cast date columns from string to datetime\n",
    "    date_columns = ['date']\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    print(\"- Date columns cast to date type\")\n",
    "    \n",
    "    # Cast ID columns to integer\n",
    "    id_columns = ['listing_id', 'id', 'reviewer_id']\n",
    "    for col in id_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce', downcast='integer').fillna(0).astype(int)\n",
    "    print(\"- ID columns cast to integer\")\n",
    "    \n",
    "    # Optional: Handle missing values in `comments`\n",
    "    if 'comments' in df.columns:\n",
    "        df['comments'] = df['comments'].fillna(\"\")\n",
    "    print(\"- Missing values in comments handled (if applicable)\")\n",
    "\n",
    "     # Add a 'city' column with the value of 'name'\n",
    "    df['city'] = name\n",
    "    print(f\"- Added 'city' column with value '{name}' for all rows\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Prague -------------\n",
      "- Date columns cast to date type\n",
      "- ID columns cast to integer\n",
      "- Missing values in comments handled (if applicable)\n",
      "- Added 'city' column with value 'Prague' for all rows\n",
      "Dataset: Barcelona -------------\n",
      "- Date columns cast to date type\n",
      "- ID columns cast to integer\n",
      "- Missing values in comments handled (if applicable)\n",
      "- Added 'city' column with value 'Barcelona' for all rows\n"
     ]
    }
   ],
   "source": [
    "# Apply the cleaning function to both datasets\n",
    "prg_reviews_cleaned = clean_reviews(prg_reviews, \"Prague\")\n",
    "bcn_reviews_cleaned = clean_reviews(bcn_reviews, \"Barcelona\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values summary for dataset: Prague -------------\n",
      "Shape: 651459 rows × 7 columns\n",
      "Series([], dtype: int64)\n",
      "Total missing values: 0/4560213 (0.00%)\n",
      "\n",
      "Missing values summary for dataset: Barcelona -------------\n",
      "Shape: 927474 rows × 7 columns\n",
      "Series([], dtype: int64)\n",
      "Total missing values: 0/6492318 (0.00%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply missing value check to both datasets\n",
    "check_missing_values(prg_reviews_cleaned, \"Prague\")\n",
    "check_missing_values(bcn_reviews_cleaned, \"Barcelona\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge `listings` and `reviews` datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the `listings` datasets by appending one dataframe after the other, with the column `city` serving for identification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged listings datasets into 'cities_listings'.\n"
     ]
    }
   ],
   "source": [
    "# Merge listings datasets\n",
    "cities_listings = pd.concat([prg_listings_cleaned, bcn_listings_cleaned], ignore_index=True)\n",
    "print(\"Merged listings datasets into 'cities_listings'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city\n",
       "Barcelona    19482\n",
       "Prague        9066\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the occurrences of each unique value in the 'city' column\n",
    "city_listings_counts = cities_listings['city'].value_counts()\n",
    "city_listings_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the `reviews` datasets by appending one dataframe after the other, with the column `city` serving for identification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged reviews datasets into 'cities_reviews'.\n"
     ]
    }
   ],
   "source": [
    "# Merge reviews datasets\n",
    "cities_reviews = pd.concat([prg_reviews_cleaned, bcn_reviews_cleaned], ignore_index=True)\n",
    "print(\"Merged reviews datasets into 'cities_reviews'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city\n",
       "Barcelona    927474\n",
       "Prague       651459\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the occurrences of each unique value in the 'city' column\n",
    "city_reviews_counts = cities_reviews['city'].value_counts()\n",
    "city_reviews_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded cities_listings.csv to container cleansed-layer-airbnb.\n",
      "Uploaded cities_reviews.csv to container cleansed-layer-airbnb.\n"
     ]
    }
   ],
   "source": [
    "container_name = \"cleansed-layer-airbnb\"\n",
    "\n",
    "# Function to upload a DataFrame to Azure Blob Storage\n",
    "def upload_dataframe_to_blob(dataframe, container_name, blob_name, connection_string):\n",
    "    # Convert the DataFrame to a CSV string\n",
    "    csv_data = dataframe.to_csv(index=False)\n",
    "    \n",
    "    # Encode the CSV string to bytes\n",
    "    csv_bytes = csv_data.encode('utf-8')\n",
    "    \n",
    "    # Create a BlobServiceClient\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "    \n",
    "    # Get a blob client\n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "    \n",
    "    # Upload the CSV data\n",
    "    blob_client.upload_blob(csv_bytes, blob_type=\"BlockBlob\", overwrite=True)\n",
    "    print(f\"Uploaded {blob_name} to container {container_name}.\")\n",
    "\n",
    "# File names for the blobs\n",
    "listings_blob_name = \"cities_listings.csv\"\n",
    "reviews_blob_name = \"cities_reviews.csv\"\n",
    "\n",
    "# Upload the merged datasets\n",
    "upload_dataframe_to_blob(cities_listings, container_name, listings_blob_name, connection_string)\n",
    "upload_dataframe_to_blob(cities_reviews, container_name, reviews_blob_name, connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Daniel_Ingestion_Blob_InsideAirbnb",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
