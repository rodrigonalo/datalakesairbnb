{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02a8a99f-e52c-42b8-b04a-dfbe52baf852",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Part 1: Ingestion of Data via URL + Unzipping .gz and Loading on Azure Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75eaf0cc-b7d0-4b9a-816c-e4407b30c75d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import gzip\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8892bb7-60f5-4ea2-83f7-5ecec6d6eb37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Connection settings and establishment of connection to blob storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8a1e8e4-d5b4-4322-8929-f3f36f96263c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Azure Blob Storage\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=datalakestoragerentscape;AccountKey=w6Edf3np1A18vQIei31unvKWjGpyDUBqexvVauAwCeqOmnF1Bq7WsIEVplSEW+hT0q4ZzDi2KNh4+AStrOcI6g==;EndpointSuffix=core.windows.net\"\n",
    "container_name = \"rentscape-blob\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18a2e6c0-e1c1-40f0-a841-931c45b52881",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the BlobServiceClient\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "110cb16e-6a2b-40d5-af51-9246f154ce20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Dictionary containing paths to URLs of .gz files and target location in blob storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f69d8609-9e29-44e5-b249-9c640f0d045e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the URLs and corresponding blob names for each file\n",
    "file_info = [\n",
    "    {\n",
    "        \"url\": \"https://data.insideairbnb.com/spain/catalonia/barcelona/2024-09-06/data/listings.csv.gz\",\n",
    "        \"blob_name\": \"barcelona_listings.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://data.insideairbnb.com/spain/catalonia/barcelona/2024-09-06/data/reviews.csv.gz\",\n",
    "        \"blob_name\": \"barcelona_reviews.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://data.insideairbnb.com/czech-republic/prague/prague/2024-06-24/data/listings.csv.gz\",\n",
    "        \"blob_name\": \"prague_listings.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://data.insideairbnb.com/czech-republic/prague/prague/2024-06-24/data/reviews.csv.gz\",\n",
    "        \"blob_name\": \"prague_reviews.csv\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "533c2ad3-a68d-494d-8689-654a31ae13c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This code processes a list of URLs pointing to .gz compressed CSV files, decompresses them, and uploads the decompressed CSV data to Azure Blob Storage:\n",
    "\n",
    "- Download the .gz File: For each file URL in file_info, it sends a request to download the file. If the download is successful, it proceeds; otherwise, it skips to the next file.\n",
    "\n",
    "- Decompress the .gz Content: The downloaded content is opened in text mode ('rt') with UTF-8 encoding specified. Using gzip.open() with io.BytesIO() allows decompression directly in memory without saving the file locally. If thereâ€™s an error during decompression, it moves to the next file.\n",
    "\n",
    "- Upload to Azure Blob Storage: The decompressed CSV data (stored as plain text) is then uploaded to Azure Blob Storage with a specified blob_name using the Azure Blob client. If an error occurs during upload, the code logs it and proceeds with the next file.\n",
    "\n",
    "Finally, after all files are processed, it prints a message indicating completion. This setup efficiently handles multiple files, using in-memory processing and error handling for each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5969b5ef-07b1-4d16-9d31-672467eb0022",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded barcelona_listings.csv successfully.\n",
      "Uploaded decompressed CSV content to barcelona_listings.csv in Azure Blob Storage.\n",
      "Downloaded barcelona_reviews.csv successfully.\n",
      "Uploaded decompressed CSV content to barcelona_reviews.csv in Azure Blob Storage.\n",
      "Downloaded prague_listings.csv successfully.\n",
      "Uploaded decompressed CSV content to prague_listings.csv in Azure Blob Storage.\n",
      "Downloaded prague_reviews.csv successfully.\n",
      "Uploaded decompressed CSV content to prague_reviews.csv in Azure Blob Storage.\n",
      "File upload process completed for all files.\n"
     ]
    }
   ],
   "source": [
    "# Process each URL and upload the decompressed CSV to Azure Blob Storage\n",
    "for file in file_info:\n",
    "    url = file[\"url\"]\n",
    "    blob_name = file[\"blob_name\"]\n",
    "    \n",
    "    # Step 1: Download the .gz file from the URL\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Downloaded {blob_name} successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to download {blob_name}. Status code: {response.status_code}\")\n",
    "        continue\n",
    "\n",
    "    # Step 2: Decompress the .gz content with utf-8 encoding\n",
    "    try:\n",
    "        with gzip.open(io.BytesIO(response.content), 'rt', encoding='utf-8', errors='ignore') as f:\n",
    "            csv_content = f.read()  # Read the decompressed CSV content as text\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to decompress {blob_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Step 3: Upload the decompressed CSV content to Azure Blob Storage\n",
    "    try:\n",
    "        blob_client = container_client.get_blob_client(blob_name)\n",
    "        blob_client.upload_blob(csv_content, overwrite=True)\n",
    "        print(f\"Uploaded decompressed CSV content to {blob_name} in Azure Blob Storage.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to upload {blob_name}: {e}\")\n",
    "\n",
    "print(\"File upload process completed for all files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "455a6c7f-c689-47e2-9463-54c99e69d773",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Daniel_Ingestion_Blob_InsideAirbnb",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
